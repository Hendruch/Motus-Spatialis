{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the moonquake type mapping CSV file\n",
    "mapping_file = 'archive/data/lunar/training/catalogs/apollo12_catalog_GradeA_final.csv'  # Replace with your path\n",
    "mapping_df = pd.read_csv(mapping_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load individual moonquake CSV files and process them\n",
    "def process_moonquake_file(filepath):\n",
    "    # Load moonquake data\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    # Use the correct column name for time_abs\n",
    "    time_column = str.format('time_abs(%Y-%m-%dT%H:%M:%S.%f)')\n",
    "    \n",
    "    # Check if the time_abs column exists\n",
    "    if time_column not in df.columns:\n",
    "        print(f\"Warning: '{time_column}' column missing in file {filepath}\")\n",
    "        return None\n",
    "    \n",
    "    # Parse time features from the absolute time\n",
    "    df[time_column] = pd.to_datetime(df[time_column], format='%Y-%m-%dT%H:%M:%S.%f')\n",
    "    df['hour'] = df[time_column].dt.hour\n",
    "    df['day'] = df[time_column].dt.day\n",
    "    df['month'] = df[time_column].dt.month\n",
    "    \n",
    "    # Calculate velocity statistics\n",
    "    velocity_stats = {\n",
    "        'velocity_mean': df['velocity(m/s)'].mean(),\n",
    "        'velocity_max': df['velocity(m/s)'].max(),\n",
    "        'velocity_min': df['velocity(m/s)'].min(),\n",
    "        'velocity_std': df['velocity(m/s)'].std(),\n",
    "    }\n",
    "    \n",
    "    # Combine with time-based features (you can add more if needed)\n",
    "    features = {\n",
    "        'hour': df['hour'].iloc[0],\n",
    "        'day': df['day'].iloc[0],\n",
    "        'month': df['month'].iloc[0]\n",
    "    }\n",
    "    \n",
    "    features.update(velocity_stats)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where moonquake CSV files are stored\n",
    "moonquake_data_dir = 'archive/data/lunar/training/data/S12_GradeA'  # Replace with your directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Merge moonquake data with the mapping\n",
    "data = []\n",
    "\n",
    "for _, row in mapping_df.iterrows():\n",
    "    filename = row['filename']\n",
    "    mq_type = row['mq_type']\n",
    "    \n",
    "    # Load and process the corresponding moonquake file\n",
    "    moonquake_filepath = os.path.join(moonquake_data_dir, filename+'.csv')\n",
    "    if os.path.exists(moonquake_filepath):\n",
    "        features = process_moonquake_file(moonquake_filepath)\n",
    "        features['mq_type'] = mq_type\n",
    "        data.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of dictionaries into a DataFrame\n",
    "moonquake_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>velocity_mean</th>\n",
       "      <th>velocity_max</th>\n",
       "      <th>velocity_min</th>\n",
       "      <th>velocity_std</th>\n",
       "      <th>mq_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>-8.443134e-13</td>\n",
       "      <td>7.874026e-09</td>\n",
       "      <td>-8.185283e-09</td>\n",
       "      <td>3.530059e-10</td>\n",
       "      <td>impact_mq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.939339e-12</td>\n",
       "      <td>4.707866e-09</td>\n",
       "      <td>-4.603228e-09</td>\n",
       "      <td>3.865140e-10</td>\n",
       "      <td>impact_mq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.980386e-13</td>\n",
       "      <td>5.969005e-09</td>\n",
       "      <td>-6.144452e-09</td>\n",
       "      <td>3.219585e-10</td>\n",
       "      <td>impact_mq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.547089e-13</td>\n",
       "      <td>6.853803e-09</td>\n",
       "      <td>-6.155705e-09</td>\n",
       "      <td>3.383785e-10</td>\n",
       "      <td>impact_mq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.921802e-13</td>\n",
       "      <td>5.491012e-09</td>\n",
       "      <td>-4.475551e-09</td>\n",
       "      <td>3.009882e-10</td>\n",
       "      <td>deep_mq</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hour  day  month  velocity_mean  velocity_max  velocity_min  velocity_std  \\\n",
       "0     0   19      1  -8.443134e-13  7.874026e-09 -8.185283e-09  3.530059e-10   \n",
       "1     0   25      3  -1.939339e-12  4.707866e-09 -4.603228e-09  3.865140e-10   \n",
       "2     0   26      3  -2.980386e-13  5.969005e-09 -6.144452e-09  3.219585e-10   \n",
       "3     0   25      4  -1.547089e-13  6.853803e-09 -6.155705e-09  3.383785e-10   \n",
       "4     0   26      4  -6.921802e-13  5.491012e-09 -4.475551e-09  3.009882e-10   \n",
       "\n",
       "     mq_type  \n",
       "0  impact_mq  \n",
       "1  impact_mq  \n",
       "2  impact_mq  \n",
       "3  impact_mq  \n",
       "4    deep_mq  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moonquake_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Encode the target labels (moonquake types)\n",
    "encoder = LabelEncoder()\n",
    "moonquake_df['mq_type_encoded'] = encoder.fit_transform(moonquake_df['mq_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Prepare the sequences of data (for RNN)\n",
    "def create_sequences(data, sequence_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        seq = data[i:i + sequence_length]\n",
    "        target = data['mq_type_encoded'].iloc[i + sequence_length]\n",
    "        sequences.append(seq)\n",
    "        targets.append(target)\n",
    "    return np.array(sequences), np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you want to use a window of 10 time steps to predict the next event type\n",
    "sequence_length = 10\n",
    "\n",
    "# Prepare the sequence data\n",
    "features = moonquake_df[['velocity_mean','velocity_max','velocity_min','velocity_std','mq_type_encoded']]  # Use velocity or more features if needed\n",
    "X, y = create_sequences(features, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate number of samples\n",
    "n_samples = X_train.shape[0]  # or you can use len(X_train)\n",
    "n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reshape into (n_samples, sequence_length, n_features)\n",
    "X_train = X_train.reshape((n_samples, sequence_length, 5))\n",
    "\n",
    "# Similarly, reshape X_test\n",
    "n_test_samples = X_test.shape[0]\n",
    "X_test = X_test.reshape((n_test_samples, sequence_length, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Build the RNN model (LSTM)\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hendrick/Development/Nasa Space Apps/env/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Add an LSTM layer\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(sequence_length, 5)))\n",
    "model.add(Dropout(0.2))  # Dropout to prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a second LSTM layer (optional, for deeper RNNs)\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Add a Dense layer for output\n",
    "model.add(Dense(units=len(encoder.classes_), activation='softmax'))  # Multiclass classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - accuracy: 0.6154 - loss: 1.0193 - val_accuracy: 0.8462 - val_loss: 0.9410\n",
      "Epoch 2/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8558 - loss: 0.9412 - val_accuracy: 0.8462 - val_loss: 0.8684\n",
      "Epoch 3/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8454 - loss: 0.8588 - val_accuracy: 0.8462 - val_loss: 0.7920\n",
      "Epoch 4/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8349 - loss: 0.7948 - val_accuracy: 0.8462 - val_loss: 0.7128\n",
      "Epoch 5/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8558 - loss: 0.6675 - val_accuracy: 0.8462 - val_loss: 0.6365\n",
      "Epoch 6/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8349 - loss: 0.6229 - val_accuracy: 0.8462 - val_loss: 0.5752\n",
      "Epoch 7/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8662 - loss: 0.5424 - val_accuracy: 0.8462 - val_loss: 0.5452\n",
      "Epoch 8/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8454 - loss: 0.5185 - val_accuracy: 0.8462 - val_loss: 0.5509\n",
      "Epoch 9/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8141 - loss: 0.6016 - val_accuracy: 0.8462 - val_loss: 0.5692\n",
      "Epoch 10/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8245 - loss: 0.6075 - val_accuracy: 0.8462 - val_loss: 0.5829\n",
      "Epoch 11/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8558 - loss: 0.5271 - val_accuracy: 0.8462 - val_loss: 0.5851\n",
      "Epoch 12/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8349 - loss: 0.5890 - val_accuracy: 0.8462 - val_loss: 0.5703\n",
      "Epoch 13/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8454 - loss: 0.5474 - val_accuracy: 0.8462 - val_loss: 0.5538\n",
      "Epoch 14/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8454 - loss: 0.5360 - val_accuracy: 0.8462 - val_loss: 0.5398\n",
      "Epoch 15/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8558 - loss: 0.5017 - val_accuracy: 0.8462 - val_loss: 0.5320\n",
      "Epoch 16/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8349 - loss: 0.5332 - val_accuracy: 0.8462 - val_loss: 0.5300\n",
      "Epoch 17/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8662 - loss: 0.4770 - val_accuracy: 0.8462 - val_loss: 0.5302\n",
      "Epoch 18/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8454 - loss: 0.5124 - val_accuracy: 0.8462 - val_loss: 0.5319\n",
      "Epoch 19/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8349 - loss: 0.5557 - val_accuracy: 0.8462 - val_loss: 0.5319\n",
      "Epoch 20/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8662 - loss: 0.4933 - val_accuracy: 0.8462 - val_loss: 0.5292\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8462 - loss: 0.5292\n",
      "Test accuracy: 84.62%\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "predicted_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Decode the predictions back to moonquake types\n",
    "predicted_mq_types = encoder.inverse_transform(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     deep_mq       0.00      0.00      0.00         2\n",
      "   impact_mq       0.85      1.00      0.92        11\n",
      "\n",
      "    accuracy                           0.85        13\n",
      "   macro avg       0.42      0.50      0.46        13\n",
      "weighted avg       0.72      0.85      0.78        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hendrick/Development/Nasa Space Apps/env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2642: UserWarning: labels size, 2, does not match size of target_names, 3\n",
      "  warnings.warn(\n",
      "/Users/hendrick/Development/Nasa Space Apps/env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/hendrick/Development/Nasa Space Apps/env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/hendrick/Development/Nasa Space Apps/env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predicted_classes, target_names=encoder.classes_, labels=np.unique(y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
